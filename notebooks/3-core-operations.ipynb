{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Core Operations in OpenCV\n",
    "===\n",
    "\n",
    "In which we learn the basic operations and arithmetic operations on images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Image Properties\n",
    "\n",
    "The shape of an image may be accessed as if accessing an array, `image.shape`. It returns a tuple of number of rows, columns, and channels (if the image is not grayscale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1182, 1000, 3)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('../assets/bernie.jpg')\n",
    "\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the image is grayscale, it will only return `ROWxCOL`. Thus, it may be used for checking if an image is grayscale or colored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the total number of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3546000\n"
     ]
    }
   ],
   "source": [
    "print(image.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the image data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(image.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access and Modify Pixel Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access a pixel value by its row and column coordinates. For RGB image, it returns an array of Blue, Green, Red values. For grayscale image, just corresponding intensity is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel = image[261, 302]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[157 187 236]\n"
     ]
    }
   ],
   "source": [
    "print(pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n",
      "187\n",
      "236\n"
     ]
    }
   ],
   "source": [
    "# access only blue pixel\n",
    "print(pixel[0])\n",
    "\n",
    "# access only green pixel\n",
    "print(pixel[1])\n",
    "\n",
    "# access only red pixel\n",
    "print(pixel[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('pixel', pixel)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel = 0\n",
    "\n",
    "cv2.imshow('pixel', pixel)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the region of pixels pertaining to face only\n",
    "cropped = image[302:(302 + 322), 261:(261 + 339)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow('cropped', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('image', image)\n",
    "cv2.imshow('cropped', cropped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_center = False\n",
    "region = cv2.selectROI(image, from_center)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261, 285, 344, 376)\n"
     ]
    }
   ],
   "source": [
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped = image[region[1]:(region[1] + region[3]), region[0]:(region[0] + region[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow('cropped', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('image', image)\n",
    "cv2.imshow('cropped', cropped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting and Merging Image Channels\n",
    "\n",
    "The RGB channels can be split into their individual planes when needed. It can also be merged to form RGB again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue, green, red = cv2.split(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('blue_channel', blue)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('red_channel', red)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('green_channel', green)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.merge((blue, green, red))\n",
    "\n",
    "cv2.imshow('merged_back', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since using `cv2.split()` and `cv2.merge()` are both computationally intensive, we can use NumPy slicing instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue = image[:, :, 0]\n",
    "\n",
    "cv2.imshow('blue_channel', blue)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "green = image[:, :, 1]\n",
    "\n",
    "cv2.imshow('green_channel', green)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = image[:, :, 2]\n",
    "\n",
    "cv2.imshow('red_channel', red)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use NumPy slicing as a way to access an image channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify red channel\n",
    "image[:, :, 2] = 0\n",
    "\n",
    "cv2.imshow('modified_red_channel', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Addition\n",
    "\n",
    "We can add images by using `cv2.add()`. But both images must have the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bernie = cv2.imread('../assets/bernie.jpg')\n",
    "howie = cv2.imread('../assets/howie.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bernie_howie = cv2.add(bernie, howie)\n",
    "\n",
    "cv2.imshow('add', bernie_howie)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Blending\n",
    "\n",
    "This is also image addition, but there are different weights given to images. The equation is as follows\n",
    "\n",
    "$$ g(x) = (1 - \\alpha)\\ f_{0}(x) + \\alpha\\ f_{1}(x) $$ \n",
    "\n",
    "By varying $\\alpha$ from 0 $\\rightarrow$ 1, it will give a \"transition feel\" between the images.\n",
    "\n",
    "For our example, we take two images to blend together. We assign a weight of 0.7 to the first image, and 0.3 to the second. Using `cv2.addWeighted()` applies the following equation\n",
    "\n",
    "$$ dst = \\alpha \\cdot img1 + \\beta \\cdot img2 + \\gamma $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend = cv2.addWeighted(bernie, 0.7, howie, 0.3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('blend', blend)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitwise Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the logo to use \n",
    "big_bang = cv2.imread('../assets/big-bang.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(823, 638, 3)\n"
     ]
    }
   ],
   "source": [
    "# display the logo shape\n",
    "print(big_bang.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knowing the `bernie` has a shape (1182, 1000, 3)\n",
    "# the logo is quite big for the image\n",
    "# let's resize it\n",
    "big_bang = cv2.resize(big_bang, (int(big_bang.shape[1] * 0.25), int(big_bang.shape[0] * 0.25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205, 159, 3)\n"
     ]
    }
   ],
   "source": [
    "print(big_bang.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the properties of the logo\n",
    "rows, cols, channels = big_bang.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's put the logo at the top-left corner\n",
    "roi = bernie[0:rows, 0:cols]\n",
    "\n",
    "cv2.imshow('roi', roi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mask of the logo\n",
    "\n",
    "# convert the image to grayscale for thresholding\n",
    "bigbang_gray = cv2.cvtColor(big_bang, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# first argument is the source image\n",
    "# second argument is the threshold value\n",
    "# third argument is the value to use if threshold is reached\n",
    "# cv2.THRESH_BINARY_INV reverses the condition of the third argument\n",
    "ret, mask = cv2.threshold(bigbang_gray, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the inverse mask\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "cv2.imshow('mask_inv', mask_inv)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# black out the area of logo in ROI\n",
    "bernie_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "\n",
    "cv2.imshow('bernie_bg', bernie_bg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take region of logo from logo image\n",
    "bigbang_fg = cv2.bitwise_and(big_bang, big_bang, mask=mask)\n",
    "\n",
    "cv2.imshow('bigbang_fg', bigbang_fg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put logo on region of interest\n",
    "dst = cv2.add(bernie_bg, bigbang_fg)\n",
    "bernie[0:rows, 0:cols] = dst\n",
    "\n",
    "cv2.namedWindow('bernie_bigbang', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('bernie_bigbang', bernie)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Take the best portrait of yourself, download the logo of Accenture from here: https://tinyurl.com/y8dz29u3. Then, put the logo on your chosen portrait using bitwise operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise on Drawing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_bang = cv2.imread('../assets/big-bang.jpg')\n",
    "\n",
    "big_bang = cv2.resize(big_bang, (int(big_bang.shape[1] * 0.25), int(big_bang.shape[0] * 0.25)))\n",
    "\n",
    "rows, cols, _ = big_bang.shape\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    roi = frame[0:rows, 0:cols]\n",
    "    \n",
    "    bigbang_gray = cv2.cvtColor(big_bang, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    ret, mask = cv2.threshold(bigbang_gray, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "    \n",
    "    frame_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "    bigbang_fg = cv2.bitwise_and(big_bang, big_bang, mask=mask)\n",
    "    \n",
    "    dst = cv2.add(frame_bg, bigbang_fg)\n",
    "    frame[0:rows, 0:cols] = dst\n",
    "    \n",
    "    cv2.imshow('bitwise', frame)\n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    \n",
    "    if k == ord('q') or k == 27:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise on Image Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bernie = cv2.imread('../assets/bernie.jpg')\n",
    "\n",
    "cap = cv2.VideoCapture(-1)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    rows, cols, _ = frame.shape\n",
    "    bernie = cv2.resize(bernie, (int(cols), int(rows)))\n",
    "    blend = cv2.addWeighted(frame, 0.8, bernie, 0.2, 0)\n",
    "    cv2.imshow('blend', blend)\n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    \n",
    "    if k == ord('q') or k == 27:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create VideoCapture object for webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def apply_invert(frame):\n",
    "    # return inverted image\n",
    "    return cv2.bitwise_not(frame)\n",
    "\n",
    "def apply_sepia(frame, intensity=0.5):\n",
    "    blue = 20\n",
    "    green = 66\n",
    "    red = 112\n",
    "    # use the sepia profile as overlay\n",
    "    frame = apply_color_overlay(frame, intensity=intensity, blue=blue, green=green, red=red)\n",
    "    return frame\n",
    "\n",
    "def verify_alpha_channel(frame):\n",
    "    try:\n",
    "        frame.shape[3]\n",
    "    except IndexError:\n",
    "        # convert the frame to have an alpha channel\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2BGRA)\n",
    "    return frame\n",
    "\n",
    "def apply_color_overlay(frame, intensity=0.5, blue=0, green=0, red=0):\n",
    "    frame = verify_alpha_channel(frame)\n",
    "    frame_height, frame_width, frame_channel = frame.shape\n",
    "    sepia_bgra = (blue, green, red, 1)\n",
    "\n",
    "    # create overlay based on color profile from (blue, green, red)\n",
    "    overlay = np.full((frame_height, frame_width, 4), sepia_bgra, dtype='uint8')\n",
    "\n",
    "    # add sepia overlay on frame\n",
    "    frame = cv2.addWeighted(overlay, intensity, frame, 1.0, 0)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)\n",
    "    return frame\n",
    "\n",
    "def alpha_blend(frame_1, frame_2, mask):\n",
    "    # isolate the white parts\n",
    "    alpha = mask / 255.0\n",
    "    \n",
    "    # blur out the background, with object of focus being clear\n",
    "    blended = cv2.convertScaleAbs(frame_1 * (1 - alpha) + (frame_2 * alpha))\n",
    "    \n",
    "    return blended\n",
    "\n",
    "def apply_portrait_mode(frame):\n",
    "    frame = verify_alpha_channel(frame)\n",
    "    \n",
    "    # convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # create a mask that is based on threshold of 120\n",
    "    # that is, if a pixel reaches or is greater than 120,\n",
    "    # modify it to have 255\n",
    "    _, mask = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # modify the mask to have an alpha channel\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGRA)\n",
    "    \n",
    "    # perform gaussian blurring with (21, 21) kernel\n",
    "    # 0 stddev\n",
    "    blurred = cv2.GaussianBlur(frame, (21, 21), 0)\n",
    "\n",
    "    # blend the original frame with the blurred frame\n",
    "    # with mask to use for isolating the object of focus\n",
    "    blended = alpha_blend(frame, blurred, mask)\n",
    "    \n",
    "    # convert frame back to BGR, i.e. w/o alpha\n",
    "    frame = cv2.cvtColor(blended, cv2.COLOR_BGRA2BGR)\n",
    "    return frame\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    invert = apply_invert(frame)\n",
    "    sepia = apply_sepia(frame)\n",
    "    redish_color = apply_color_overlay(frame, intensity=0.5, red=230, blue=10)\n",
    "    portrait_mode = apply_portrait_mode(frame)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('invert', invert)\n",
    "    cv2.imshow('sepia', sepia)\n",
    "    cv2.imshow('redish_color', redish_color)\n",
    "    cv2.imshow('portrait_mode', portrait_mode)\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "\n",
    "    if k == ord('q') or k == 27:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
